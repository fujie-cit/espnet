{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disfluencyの方は，脱落誤りが実質的にはあまり問題のない誤りなので，区別してカウントする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def make_result_df(result_file):\n",
    "    with open(result_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    results = {'F': {}, 'D': {}}\n",
    "\n",
    "    id = None\n",
    "    for line in tqdm.tqdm(lines):\n",
    "        if line.startswith(\"id\"):\n",
    "            id = line.split()[1][1:-1].upper()\n",
    "            ref = None\n",
    "            hyp = None\n",
    "        elif line.startswith(\"REF:\"):\n",
    "            ref = line.split()[1:]\n",
    "            continue\n",
    "        elif line.startswith(\"HYP:\"):\n",
    "            hyp = line.split()[1:]\n",
    "            continue\n",
    "        if id is not None and ref is not None and hyp is not None:\n",
    "            for key in ('F', 'D'):\n",
    "                tp, fn, fp, dl = 0, 0, 0, 0\n",
    "                for r, h in zip(ref, hyp):\n",
    "                    r = r.upper()\n",
    "                    h = h.upper()\n",
    "                    if key in r:\n",
    "                        if key in h:\n",
    "                            tp += 1\n",
    "                        else:\n",
    "                            fn += 1\n",
    "                            if '*' in h: # 単純脱落誤り\n",
    "                                dl += 1\n",
    "                    else:\n",
    "                        if key in h:\n",
    "                            fp += 1\n",
    "                results[key][id] = {'TP': tp, 'FN': fn, 'FP': fp, 'DL': dl}\n",
    "            id = None\n",
    "            ref = None\n",
    "            hyp = None\n",
    "\n",
    "    result_dfs = {}\n",
    "    for key, value in results.items():\n",
    "        df = pd.DataFrame(value).T\n",
    "\n",
    "        # dfの各列の合計値を，ALLというインデクスで一番最後の行に追加する\n",
    "        df.loc['ALL'] = df.sum()\n",
    "        # Precision, Recall, F1を計算する．ただしTP, FN, FPが0の場合は0とする．\n",
    "        df['Precision'] = (df['TP'] / (df['TP'] + df['FP'])).fillna(0)\n",
    "        df['Recall'] = (df['TP'] / (df['TP'] + df['FN'])).fillna(0)\n",
    "        df['F1'] = (2 * df['Precision'] * df['Recall'] / (df['Precision'] + df['Recall'])).fillna(0)\n",
    "        \n",
    "\n",
    "        result_dfs[key] = df\n",
    "\n",
    "    return result_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8501/8501 [00:00<00:00, 137719.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: eval1, Type: F\n",
      "{'TP': 2929.0, 'FN': 297.0, 'FP': 166.0, 'DL': 231.0, 'Precision': 0.9463651050080776, 'Recall': 0.9079355238685679, 'F1': 0.9267520961873121}\n",
      "Saved to 002_cbs081616hop128_transducer_with_lm_eval1_F.csv\n",
      "Eval: eval1, Type: D\n",
      "{'TP': 216.0, 'FN': 368.0, 'FP': 47.0, 'DL': 232.0, 'Precision': 0.8212927756653993, 'Recall': 0.3698630136986301, 'F1': 0.5100354191263282}\n",
      "Saved to 002_cbs081616hop128_transducer_with_lm_eval1_D.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8579/8579 [00:00<00:00, 221101.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: eval2, Type: F\n",
      "{'TP': 2284.0, 'FN': 198.0, 'FP': 128.0, 'DL': 152.0, 'Precision': 0.9469320066334992, 'Recall': 0.9202256244963739, 'F1': 0.93338782182264}\n",
      "Saved to 002_cbs081616hop128_transducer_with_lm_eval2_F.csv\n",
      "Eval: eval2, Type: D\n",
      "{'TP': 263.0, 'FN': 290.0, 'FP': 85.0, 'DL': 145.0, 'Precision': 0.7557471264367817, 'Recall': 0.4755877034358047, 'F1': 0.5837957824639289}\n",
      "Saved to 002_cbs081616hop128_transducer_with_lm_eval2_D.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8723/8723 [00:00<00:00, 333806.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: eval3, Type: F\n",
      "{'TP': 1577.0, 'FN': 123.0, 'FP': 199.0, 'DL': 95.0, 'Precision': 0.8879504504504504, 'Recall': 0.9276470588235294, 'F1': 0.9073647871116226}\n",
      "Saved to 002_cbs081616hop128_transducer_with_lm_eval3_F.csv\n",
      "Eval: eval3, Type: D\n",
      "{'TP': 93.0, 'FN': 174.0, 'FP': 31.0, 'DL': 84.0, 'Precision': 0.75, 'Recall': 0.34831460674157305, 'F1': 0.4757033248081842}\n",
      "Saved to 002_cbs081616hop128_transducer_with_lm_eval3_D.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "exp_name = \"asr_train_asr_cbs_transducer_081616_hop128/cbs_20epoch_with_lm\"\n",
    "out_name = \"002_cbs081616hop128_transducer_with_lm\"\n",
    "\n",
    "for eval_name in [\"eval1\", \"eval2\", \"eval3\"]:\n",
    "    eval_dir = os.path.join(\"exp\", exp_name, eval_name, \"score_wer\")\n",
    "    result_file = os.path.join(eval_dir, \"result.txt\")\n",
    "    result_dfs = make_result_df(result_file)\n",
    "\n",
    "    for key, df in result_dfs.items():\n",
    "        print(f\"Eval: {eval_name}, Type: {key}\")\n",
    "        print(df.loc['ALL'].to_dict())\n",
    "        out_csv_name = f\"{out_name}_{eval_name}_{key}.csv\"\n",
    "        df.to_csv(out_csv_name)\n",
    "        print(f\"Saved to {out_csv_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
