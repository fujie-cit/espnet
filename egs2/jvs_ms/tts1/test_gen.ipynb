{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JVS100人分で学習したモデルの音声合成デモ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from espnet2.bin.tts_inference import Text2Speech\n",
    "from espnet2.train.dataset import ESPnetDataset\n",
    "import os\n",
    "\n",
    "# 実験ディレクトリのパス\n",
    "exp_dir = \"./exp/tts_finetune_xvector_vits_raw_phn_jaconv_pyopenjtalk_prosody\"\n",
    "\n",
    "# 学習設定ファイルのパス\n",
    "train_config_path = os.path.join(exp_dir, \"config.yaml\")\n",
    "\n",
    "# モデルファイルのパス\n",
    "model_path = os.path.join(exp_dir, \"train.total_count.ave.pth\")\n",
    "# model_path = os.path.join(exp_dir, \"train.total_count.best.pth\")\n",
    "# model_path = os.path.join(exp_dir, \"latest.pth\")\n",
    "\n",
    "# ボコーダモデルの名前\n",
    "vocoder_tag = \"parallel_wavegan/jsut_parallel_wavegan.v1\"\n",
    "\n",
    "# text2speechインスタンスの作成\n",
    "text2speech = Text2Speech.from_pretrained(\n",
    "    train_config=train_config_path,\n",
    "    model_file=model_path,\n",
    "    vocoder_tag=vocoder_tag,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X-Vectorとリアル音声のデータセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ESPnetDataset([\n",
    "    (\"./dump/22k/xvector/eval1/xvector.scp\", \"xvector\", \"kaldi_ark\"),\n",
    "    (\"./dump/22k/raw/eval1/wav.scp\", \"speech\", \"sound\")])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Audio, Markdown\n",
    "\n",
    "# i番目のデータを取得する\n",
    "#   評価セットは1人あたり5データずつあるので，5つごとに個人性が変わる\n",
    "i = 40 \n",
    "id      = dataset[i][0][:6]         # 発話IDから個人IDを取り出す\n",
    "xvector = dataset[i][1]['xvector']  # X-Vector（個人性を表すベクトル）\n",
    "speech  = dataset[i][1]['speech']   # リアル音声\n",
    "\n",
    "# 合成（spembsにxvectorを指定することで，個人性を表現する）\n",
    "result = text2speech(\"それではこれで、明日の状況の確認をお願いしようと思います\", spembs=xvector)\n",
    "\n",
    "# 合成音の表示\n",
    "display(Markdown(f\"**{id}**\"))\n",
    "display(Markdown(\"- リアル\"))\n",
    "display(Audio(speech, rate=text2speech.fs))\n",
    "display(Markdown(\"- 合成\"))\n",
    "display(Audio(result[\"wav\"].cpu(), rate=text2speech.fs))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "個人性の混合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i番目の個人性とj番目の個人性を1対1で混合する\n",
    "i, j = 40, 45\n",
    "\n",
    "id_i = dataset[i][0][:6]\n",
    "xvector_i = dataset[i][1]['xvector']\n",
    "speech_i = dataset[i][1]['speech']\n",
    "\n",
    "id_j = dataset[j][0][:6]\n",
    "xvector_j = dataset[j][1]['xvector']\n",
    "speech_j = dataset[j][1]['speech']\n",
    "\n",
    "text = \"それではこれで、明日の状況の確認をお願いしようと思います\"\n",
    "# i番目の人で合成\n",
    "result_i = text2speech(text, spembs=xvector_i)\n",
    "# j番目の人で合成\n",
    "result_j = text2speech(text, spembs=xvector_j)\n",
    "# 1対1（0.5ずつの重み）で合成\n",
    "w_i = 0.5\n",
    "result_i_j = text2speech(text, spembs=(w_i*xvector_i+(1.0-w_i)*xvector_j))\n",
    "\n",
    "display(Markdown(f\"- リアル ({id_i})\"))\n",
    "display(Audio(speech_i, rate=text2speech.fs))\n",
    "display(Markdown(f\"- リアル ({id_j})\"))\n",
    "display(Audio(speech_j, rate=text2speech.fs))\n",
    "\n",
    "display(Markdown(f\"- 合成 ({id_i})\"))\n",
    "display(Audio(result_i[\"wav\"].cpu(), rate=text2speech.fs))\n",
    "display(Markdown(f\"- 合成 ({id_j})\"))\n",
    "display(Audio(result_j[\"wav\"].cpu(), rate=text2speech.fs))\n",
    "display(Markdown(f\"- 合成 ({id_i} + {id_j})\"))\n",
    "display(Audio(result_i_j[\"wav\"].cpu(), rate=text2speech.fs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "個人性の混合（0.1ずつ重みを変えてモーフィング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i番目の人から徐々にj番目の人に移行する\n",
    "i, j = 0, 15\n",
    "\n",
    "id_i = dataset[i][0][:6]\n",
    "xvector_i = dataset[i][1]['xvector']\n",
    "speech_i = dataset[i][1]['speech']\n",
    "\n",
    "id_j = dataset[j][0][:6]\n",
    "xvector_j = dataset[j][1]['xvector']\n",
    "speech_j = dataset[j][1]['speech']\n",
    "\n",
    "display(Markdown(f\"- リアル ({id_i})\"))\n",
    "display(Audio(speech_i, rate=text2speech.fs))\n",
    "display(Markdown(f\"- リアル ({id_j})\"))\n",
    "display(Audio(speech_j, rate=text2speech.fs))\n",
    "\n",
    "# 重みを徐々に変化させて合成\n",
    "import numpy as np\n",
    "text = \"こんにちは\"\n",
    "for w_j in np.arange(0.0, 1.1, 0.1):\n",
    "    w_i = 1.0 - w_j\n",
    "    result_i_j = text2speech(text,\n",
    "                             spembs=(w_i*xvector_i+w_j*xvector_j))\n",
    "    display(Markdown(f\"- 合成 ({id_i}({w_i:.1f}) : {id_j}({w_j:.1f}))\"))\n",
    "    display(Audio(result_i_j[\"wav\"].cpu(), rate=text2speech.fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
